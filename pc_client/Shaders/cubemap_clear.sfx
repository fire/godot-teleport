//  Copyright (c) 2015-2017 Simul Software Ltd. All rights reserved.
#include "shader_platform.sl"
#include "common.sl"
#include "video_types.sl"
#include "render_states.sl"
#include "sampler_states.sl"
#include "camera_constants.sl"
#include "quaternion.sl"
#include "cubemap_constants.sl"

uniform TextureCube cubemapTexture;
uniform Texture2D<float4> perspectiveTexture; 
uniform Texture2D<float4> plainTexture; 
uniform RWStructuredBuffer<uint4> RWTagDataIDBuffer;
uniform StructuredBuffer<uint4> TagDataIDBuffer;
uniform RWTexture2DArray<uchar4> RWTextureTargetArray;
uniform StructuredBuffer<VideoTagDataCube> TagDataCubeBuffer;

vec2 OffsetScale(vec2 uv, vec4 offsc)
{
	return uv * offsc.zw + offsc.xy;
}

vec2 ViewToServerScreenSpace(vec3 pos)
{
	vec4 clip_pos = vec4(pos, 1.0);
	clip_pos = mul(serverProj, clip_pos);

	pos = clip_pos.xyz;

	// Move to NDC space
	if (clip_pos.w != 0)
	{
		pos /= clip_pos.w;
	}

	// Finally, convert to uv
	return 0.5 * (vec2(1.0, 1.0) + vec2(pos.x,-pos.y));
}

shader vec4 PS_NormalView(posTexVertexOutput IN) : SV_TARGET
{
	const float PI = 3.1415926536;
	const float TwoPI = 2.0 * PI;
	vec3 view	= TexCoordsToView(IN.texCoords);
	float phi	= atan2(-view.x, -view.y) / TwoPI;
	float theta	= acos(-view.z) / PI;
	vec2  uv	= fract(vec2(phi, theta));
	
	vec4 lookup = plainTexture.SampleLevel(wrapSamplerState, OffsetScale(uv, depthOffsetScale), 0).rgba;
	vec4 depth_lookup = plainTexture.SampleLevel(wrapSamplerState, OffsetScale(uv, depthOffsetScale), 0).rgba;
	
    return lookup*depth_lookup;
}

shader vec4 PS_UseCubemap(posTexVertexOutput IN) : SV_TARGET
{
	const float PI = 3.1415926536;
	const float TwoPI = 2.0 * PI;
	vec3 view_orig = TexCoordsToView(IN.texCoords);
	view_orig.xy = -view_orig.yx;
	view_orig.z *= -1.0;
	int id = int(TagDataIDBuffer[0].x);
	VideoTagDataCube tagData = TagDataCubeBuffer[id];
	vec3 offsetFromVideo2 = cameraPosition - tagData.cameraPosition;
	vec4 lookup = cubemapTexture.SampleLevel(cubeSamplerState, view_orig, 0.0);
	vec3 view = view_orig;
	float dist_m=0.0;
	for (int i = 0; i < 5; i++)
	{
		float depth = lookup.a;
		dist_m = 5.0+25.0 * depth;
		vec3 pos_m = dist_m * view_orig;
		pos_m += vec3(offsetFromVideo2.yxz)*step(-0.999, -depth);

		// But this does not intersect at depth. We want the vector from the original centre, of 

		// original radius to hit point
		float R = dist_m;
		float F = length(offsetFromVideo2);
		if (F > 0)
		{
			float D = -dot(normalize(offsetFromVideo2), view_orig);
			float b = F * D;
			float c = F * F - R * R;
			float U = -b + sqrt(b * b - c);
			pos_m += (U - R) * view_orig;

			view = normalize(pos_m);
			lookup = cubemapTexture.SampleLevel(cubeSamplerState, view, 0).rgba;
		}
	}
	return  lookup;
}

shader vec4 PS_UsePerspectiveOld(posTexVertexOutput IN) : SV_TARGET
{
	int id = int(TagDataIDBuffer[0].x);
	VideoTagDataCube tagData = TagDataCubeBuffer[id];
	
	// Transform to view space
	// Swizzle y and z to go from left-handed (HLSL) to engineering
	// because rotations are in engineering coordinate system.
	vec3 vec = -TexCoordsToView(IN.texCoords).xzy;
	
	vec = normalize(rotate_by_quaternion(tagData.cameraRotation, vec));

	// Transform to view space of server
	vec = normalize(rotate_by_quaternion(quat_inverse(cameraRotation), vec));

	// Finally, convert to uv
	// Swizzle back
	vec2 texCoords = ViewToServerScreenSpace(vec.xzy);

	vec4 lookup = perspectiveTexture.SampleLevel(wrapSamplerState, texCoords, 0);

	return lookup;
}

shader vec4 PS_UsePerspective(posTexVertexOutput IN) : SV_TARGET
{
	int id = int(TagDataIDBuffer[0].x);
	VideoTagDataCube tagData = TagDataCubeBuffer[id];

	// Transform to view space
	// Swizzle y and z to go from left-handed (HLSL) to engineering
	// because rotations are in engineering coordinate system.
	vec3 view_orig = TexCoordsToView(IN.texCoords).xzy;

	// Transform to world space
	view_orig = normalize(rotate_by_quaternion(tagData.cameraRotation, view_orig));

	// Transform to server camera space
	view_orig = normalize(rotate_by_quaternion(quat_inverse(cameraRotation), view_orig)).xzy;

	vec2 uv = ViewToServerScreenSpace(view_orig);
	
	vec3 offsetFromVideo = cameraPosition - tagData.cameraPosition;

	// Transform to server camera space. Saves on a rotation each iteration of the loop
	offsetFromVideo = rotate_by_quaternion(quat_inverse(cameraRotation), offsetFromVideo).xzy;

	vec4 lookup = perspectiveTexture.SampleLevel(wrapSamplerState, uv, 0);
	vec3 view = view_orig;

	float dist_m=0.0;
	float F = length(offsetFromVideo);
	if (F <= 0)
	{
		return lookup;
	}
	for (int i = 0; i < 5; i++)
	{
		float depth = lookup.a;
		dist_m = 5.0 + 25.0 * depth;
		vec3 pos_m = dist_m * view_orig;
		pos_m += offsetFromVideo * step(-0.999, -depth);

		// original radius to hit point
		float R = dist_m;
	
		float D = -dot(normalize(offsetFromVideo), view_orig);
		float b = F * D;
		float c = F * F - R * R;
		float U = -b + sqrt(b * b - c);
		pos_m += (U - R) * view_orig;

		view = normalize(pos_m);

		uv = ViewToServerScreenSpace(view);
		lookup = perspectiveTexture.SampleLevel(wrapSamplerState, uv, 0);
	}
	return lookup;
}

shader vec4 PS_ShowTexture(posTexVertexOutput IN) : SV_TARGET
{
	vec4 lookup = plainTexture.SampleLevel(wrapSamplerState, IN.texCoords, 0);
	return lookup;
}

[numthreads(16, 16, 1)]
shader void CS_Recompose(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	uint3 ThreadID = uint3(g.xy * 16 + t.xy,g.z);
	if (ThreadID.x >= targetSize || ThreadID.y >= targetSize)
		return;
	uint InputW, InputH;
	plainTexture.GetDimensions(InputW, InputH);
	uint OutputW, OutputH, OutputD;
	RWTextureTargetArray.GetDimensions(OutputW, OutputH, OutputD);
	int3 pos = int3(ThreadID);
	int2 FaceOffsets[] = { {0,0},{1,0},{2,0},{0,1},{1,1},{2,1} };
	float4 SceneColor = plainTexture.Load(int3(pos.xy+sourceOffset+ OutputW*FaceOffsets[ThreadID.z],0));
    SceneColor.rgb*=SceneColor.rgb;
	RWTextureTargetArray[pos] = SceneColor;
}

groupshared uint accumulate_position[32];
// From the encoded binary at bottom-right
[numthreads(32, 1, 1)]
shader void CS_ExtractTagDataID(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	uint2 ThreadID	= uint2(g.xy * 32 + t.xy);
	uint2 pos		= sourceOffset+4*ThreadID.xy;
	uint2 pos_x		= pos +uint2(2,2);
	// The offset is to the X component. The thread index gives us the bit mask.
	float4 lookupX	= plainTexture.Load(int3(pos_x.xy, 0));
	// Convert the green component to a 0 or 1 uint. shift to get the binary.
	int bitX		= int(lookupX.g+0.5) << int(ThreadID.x);
	accumulate_position[ThreadID.x] = uint(bitX);
	GroupMemoryBarrierWithGroupSync();
	// Now join all the bits together.
	if(ThreadID.x==0)
	{
		uint all_bits = 0;
		for(int i=0;i<32;i++)
		{
			all_bits |= accumulate_position[i];
		}
		// use w for sanity check
		RWTagDataIDBuffer[0]= uint4(all_bits, 0, 0, 110);
	}
}

[numthreads(16, 16, 1)]
shader void CS_RecomposeWithDepthAlpha(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	uint3 ThreadID = uint3(g.xy * 16 + t.xy, g.z);
	vec3 DepthMask[4];
	DepthMask[0] = vec3(1.0, 0.0, 0.0); //0,0);
	DepthMask[1] = vec3(0.0, 1.0, 0.0); //1,0);
	DepthMask[2] = vec3(0.0, 0.0, 1.0); //0,1);
	DepthMask[3] = vec3(0.0, 0.5, 0.5); //1,1);
	uint InputW, InputH;
	plainTexture.GetDimensions(InputW, InputH);
	uint OutputW, OutputH, OutputD;
	RWTextureTargetArray.GetDimensions(OutputW, OutputH, OutputD);
	int3 pos			= int3(ThreadID);
	int2 FaceOffsets[]	= { {0,0},{1,0},{2,0},{0,1},{1,1},{2,1} };
	int3 loadPos		= int3(pos.xy + OutputW * FaceOffsets[ThreadID.z], 0);
	float4 SceneColor = plainTexture.Load(loadPos);

	int2 loadDepthPos	= loadPos / 2;
	int2 offsetToPos	= pos.xy % 2;// -loadDepthPos * 2;
	loadDepthPos		+= int2(0, OutputW) * 2;	// underneath the main cube in the video texture.
	vec3 dMask			= DepthMask[offsetToPos.x];// +2 * offsetToPos.y ];
	vec3 lookupDepth	= plainTexture.Load(int3(loadDepthPos, 0)).rgb;

	float d = dot(lookupDepth, dMask);
	// RGB values must be squared here because the server used their square root to improve colour quantization in the video encoder. 
	SceneColor.rgb *= SceneColor.rgb;
	SceneColor.a = d;
	RWTextureTargetArray[pos] = SceneColor;// float4(SceneColor.rgba);
}

[numthreads(16, 16, 1)]
shader void CS_RecomposePerspective(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	int3 pos = int3(g.xy * 16 + t.xy, 0);
	uint InputW, InputH;
	plainTexture.GetDimensions(InputW, InputH);
	float4 SceneColor = plainTexture.Load(pos);
	// RGB values are squared here because the server used their square root to improve colour quantization in the video encoder. 
	SceneColor.rgb *= SceneColor.rgb;
	RWTextureTargetArray[pos] = SceneColor;
}

[numthreads(16, 16, 1)]
shader void CS_RecomposePerspectiveWithDepthAlpha(uint3 g : SV_GroupID, uint3 t : SV_GroupThreadID)
{
	int3 pos = int3(g.xy * 16 + t.xy, 0);
	vec3 DepthMask[4];
	DepthMask[0] = vec3(1.0, 0.0, 0.0); //0,0);
	DepthMask[1] = vec3(0.0, 1.0, 0.0); //1,0);
	DepthMask[2] = vec3(0.0, 0.0, 1.0); //0,1);
	DepthMask[3] = vec3(0.0, 0.5, 0.5); //1,1);

	uint OutputW, OutputH, OutputD;
	RWTextureTargetArray.GetDimensions(OutputW, OutputH, OutputD);
	float4 SceneColor = plainTexture.Load(pos);

	int2 depthPos	    = int2(0, OutputH) + (pos.xy / 2);
	int2 offsetToPos	= pos.xy % 2;
	vec3 dMask			= DepthMask[offsetToPos.x];
	vec3 lookupDepth	= plainTexture.Load(int3(depthPos, 0)).rgb;

	float d = dot(lookupDepth, dMask);
	SceneColor.rgb *= SceneColor.rgb;
	SceneColor.a = d;
	RWTextureTargetArray[pos] = SceneColor;
}

VertexShader vs = CompileShader(vs_5_0, VS_SimpleFullscreen());

technique normal_view
{
	pass p0
	{
		SetRasterizerState(RenderNoCull);
		SetDepthStencilState(DisableDepth, 0);
		SetBlendState(DontBlend,vec4(0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF);
		SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_5_0, PS_NormalView()));
	}
}
technique show_texture
{
    pass p0
    {
		SetRasterizerState( RenderNoCull );
		SetDepthStencilState( DisableDepth, 0 );
		SetBlendState(DontBlend,vec4( 0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF );
        SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_5_0, PS_ShowTexture()));
    }
}
technique use_cubemap
{
    pass p0
    {
		SetRasterizerState( RenderNoCull );
		SetDepthStencilState( DisableDepth, 0 );
		SetBlendState(DontBlend,vec4( 0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF );
        SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_5_0, PS_UseCubemap()));
    }
}
technique use_perspective
{
    pass p0
    {
		SetRasterizerState( RenderNoCull );
		SetDepthStencilState( DisableDepth, 0 );
		SetBlendState(DontBlend,vec4( 0.0, 0.0, 0.0, 0.0), 0xFFFFFFFF );
        SetGeometryShader(NULL);
		SetVertexShader(vs);
		SetPixelShader(CompileShader(ps_5_0, PS_UsePerspective()));
    }
}
technique recompose
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_5_0, CS_Recompose()));
	}
}
technique extract_tag_data_id 
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_5_0, CS_ExtractTagDataID()));
	}
}
technique recompose_with_depth_alpha
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_5_0, CS_RecomposeWithDepthAlpha()));
	}
}
technique recompose_perspective
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_5_0, CS_RecomposePerspective()));
	}
}
technique recompose_perspective_with_depth_alpha
{
	pass p0
	{
		SetComputeShader(CompileShader(cs_5_0, CS_RecomposePerspectiveWithDepthAlpha()));
	}
}